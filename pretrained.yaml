base_model_name: "hfl/chinese-roberta-wwm-ext" 
corpus_file: "data/address.txt"
seed: 2025
num_epochs: 2
batch_size: 16
max_length: 128
learning_rate: 5.0e-5
weight_decay: 0.01
adam_epsilon: 1.0e-8
max_grad_norm: 1.0
warmup_steps: 0
mask_probability: 0.15
